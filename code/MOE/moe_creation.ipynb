{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers peft bitsandbytes accelerate trl pydantic-settings scipy codebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install -q --no-deps trl peft accelerate bitsandbytes\n",
    "!pip install -q xformers==0.0.22.post7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE QUANTIZATION HERE. Choose from (\"none\" | \"8bit\" | \"4bit\")\n",
    "QUANTIZATION = \"4bit\"#DO NOT CHANGE\n",
    "DATASET = \"codeparrot/xlcost-text-to-code\" #DO NOT CHANGE\n",
    "TESTSIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE THE FOLLOWING\n",
    "EXPERT = \"python\" #python, cpp, java, javascript, etc.\n",
    "MODELTYPE = \"FINETUNED\" #BASE or FINETUNED or MOE\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "loramodel = f\"mistral-7b-{EXPERT}-LORA-4bit\"\n",
    "lorarepo = f'santoshsto/{loramodel}'\n",
    "newmodel = f'mistral-7b-{EXPERT}-{MODELTYPE}-4bit'\n",
    "PARTITION = \"Python-program-level\" #java-program-level etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 3.92M/3.92M [00:00<00:00, 13.3MB/s]\n",
      "Downloading data: 100%|██████████| 357k/357k [00:00<00:00, 8.90MB/s]\n",
      "Downloading data: 100%|██████████| 200k/200k [00:00<00:00, 976kB/s]\n",
      "Generating train split: 100%|██████████| 9263/9263 [00:00<00:00, 362603.13 examples/s]\n",
      "Generating test split: 100%|██████████| 887/887 [00:00<00:00, 274868.68 examples/s]\n",
      "Generating validation split: 100%|██████████| 472/472 [00:00<00:00, 213055.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(DATASET, PARTITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Minimum sum possible by removing all occurrences of any array element | Function to find minimum sum after deletion ; Stores frequency of array elements ; Traverse the array ; Calculate sum ; Update frequency of the current element ; Stores the minimum sum required ; Traverse map ; Find the minimum sum obtained ; Return minimum sum ; Input array ; Size of array',\n",
       " 'code': \"def minSum ( A , N ) : NEW_LINE INDENT mp = { } NEW_LINE sum = 0 NEW_LINE for i in range ( N ) : NEW_LINE INDENT sum += A [ i ] NEW_LINE if A [ i ] in mp : NEW_LINE INDENT mp [ A [ i ] ] += 1 NEW_LINE DEDENT else : NEW_LINE INDENT mp [ A [ i ] ] = 1 NEW_LINE DEDENT DEDENT minSum = float ( ' inf ' ) NEW_LINE for it in mp : NEW_LINE INDENT minSum = min ( minSum , sum - ( it * mp [ it ] ) ) NEW_LINE DEDENT return minSum NEW_LINE DEDENT arr = [ 4 , 5 , 6 , 6 ] NEW_LINE N = len ( arr ) NEW_LINE print ( minSum ( arr , N ) ) NEW_LINE\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data[\"train\"]\n",
    "eval_dataset = data[\"validation\"]\n",
    "test_dataset = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'code'],\n",
      "    num_rows: 9263\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'code'],\n",
      "    num_rows: 472\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'code'],\n",
      "    num_rows: 887\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(eval_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:49<00:00, 54.92s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "total_params = parameters_to_vector(base_model.parameters()).numel()\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model: mistralai/Mistral-7B-v0.1\n",
      "Adapeter: santoshsto/mistral-7b-python-LORA-4bit\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Model: {model_id}')\n",
    "print(f'Adapeter: {lorarepo}')\n",
    "model_to_merge = PeftModel.from_pretrained(base_model, lorarepo)\n",
    "model = model_to_merge.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(newmodel, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(newmodel, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"<s>[INST] Write a {EXPERT} program to complete the following. Minimum sum possible by removing all occurrences of any array element | Function to find minimum sum after deletion ; Stores frequency of array elements ; Traverse the array ; Calculate sum ; Update frequency of the current element ; Stores the minimum sum required ; Traverse map ; Find the minimum sum obtained ; Return minimum sum ; Input array ; Size of array [/INST] \\\\n code:</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  input_ids = tokenizer(eval_prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "  outputs = model.generate(input_ids=input_ids, max_new_tokens=256, do_sample=True, top_p=0.9,temperature=0.5)\n",
    "\n",
    "  print(f\"Prompt:\\n{eval_prompt}\\n\")\n",
    "  print(f\"\\nGenerated response:\\n{tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(eval_prompt):]}\")\n",
    "  print(f'''\\nGround truth:{next(iter(test_dataset))}''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
